{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "iTautcw6kSEH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "from urllib.parse import urljoin\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "homepage_url = \"http://books.toscrape.com/\"\n",
        "homepage_response = requests.get(homepage_url)\n",
        "homepage_response.encoding = 'utf-8' #per ruajtjen e cmimit\n",
        "homepage_soup = BeautifulSoup(homepage_response.text, 'html.parser')"
      ],
      "metadata": {
        "id": "0W2fPwXGkaCp"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting a category list with the category name and the corresponding link\n",
        "\n",
        "def get_categories():\n",
        "  response = requests.get(homepage_url)\n",
        "  response.encoding = 'utf-8'\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  categories_tags = soup.select_one('div.side_categories > ul > li > ul').find_all('li', recursive = False)\n",
        "  categories = {}\n",
        "  for tag in categories_tags:\n",
        "    name = tag.text.strip()\n",
        "    link = urljoin(homepage_url, tag.find('a')['href'])\n",
        "    categories[name] = link\n",
        "  return categories"
      ],
      "metadata": {
        "id": "BLEJWDEwwgoM"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get all books from all pages of a specific category\n",
        "def scrape_category(category_name, start_url):\n",
        "  books=[]\n",
        "  current_url = start_url\n",
        "\n",
        "  while current_url:\n",
        "    response = requests.get(current_url)\n",
        "    response.encoding = 'utf-8'\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    for article in soup.find_all('article', class_='product_pod'):\n",
        "      title = article.h3.a['title']\n",
        "      price = article.find('p', class_='price_color').text\n",
        "      clean_price = float(re.findall(r'[0-9.]+', price)[0])\n",
        "      #adds all books of the current page\n",
        "      books.append({'title': title, 'Price (GBP)': clean_price, 'category': category_name})\n",
        "# also checking for pagination, if there's other pages, we scrape those too\n",
        "    next_button = soup.find('li', class_='next')\n",
        "    if next_button:\n",
        "      relative_link = next_button.find('a')['href']\n",
        "      current_url = urljoin(current_url, relative_link)\n",
        "    else:\n",
        "      current_url = None\n",
        "\n",
        "  return books"
      ],
      "metadata": {
        "id": "R3AvPt8rzGLX"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_exchange_rate(api_key, base_currency, target_currency):\n",
        "  url = f\"https://v6.exchangerate-api.com/v6/{api_key}/latest/{base_currency}\"\n",
        "  response = requests.get(url)\n",
        "  data = response.json()\n",
        "\n",
        "  if data[\"result\"] == \"success\":\n",
        "    return data[\"conversion_rates\"][target_currency]\n",
        "  else:\n",
        "    print(\"Error fetching API data!\")\n",
        "    return None\n",
        "\n",
        "API_KEY = \"684805c07e933d266961ebbe\"\n",
        "\n",
        "rate = get_exchange_rate(API_KEY, \"GBP\", \"EUR\")\n",
        "\n",
        "print(rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MFlyq5s0pZe5",
        "outputId": "a4e33f90-1f0f-469a-a34b-dd2451e8fb15"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import name\n",
        "all_categories = get_categories()\n",
        "\n",
        "eur_rate = get_exchange_rate(API_KEY, \"GBP\",\"EUR\")\n",
        "\n",
        "final_data = []\n",
        "\n",
        "for category_name in all_categories:\n",
        "  print(f\"Scraping category: {category_name}\")\n",
        "  results = scrape_category(category_name, all_categories[category_name])\n",
        "  final_data.extend(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jUZyVy091y-c",
        "outputId": "bc954bc0-38c8-4b5e-d7fa-7d646625f1c3"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping category: Travel\n",
            "Scraping category: Mystery\n",
            "Scraping category: Historical Fiction\n",
            "Scraping category: Sequential Art\n",
            "Scraping category: Classics\n",
            "Scraping category: Philosophy\n",
            "Scraping category: Romance\n",
            "Scraping category: Womens Fiction\n",
            "Scraping category: Fiction\n",
            "Scraping category: Childrens\n",
            "Scraping category: Religion\n",
            "Scraping category: Nonfiction\n",
            "Scraping category: Music\n",
            "Scraping category: Default\n",
            "Scraping category: Science Fiction\n",
            "Scraping category: Sports and Games\n",
            "Scraping category: Add a comment\n",
            "Scraping category: Fantasy\n",
            "Scraping category: New Adult\n",
            "Scraping category: Young Adult\n",
            "Scraping category: Science\n",
            "Scraping category: Poetry\n",
            "Scraping category: Paranormal\n",
            "Scraping category: Art\n",
            "Scraping category: Psychology\n",
            "Scraping category: Autobiography\n",
            "Scraping category: Parenting\n",
            "Scraping category: Adult Fiction\n",
            "Scraping category: Humor\n",
            "Scraping category: Horror\n",
            "Scraping category: History\n",
            "Scraping category: Food and Drink\n",
            "Scraping category: Christian Fiction\n",
            "Scraping category: Business\n",
            "Scraping category: Biography\n",
            "Scraping category: Thriller\n",
            "Scraping category: Contemporary\n",
            "Scraping category: Spirituality\n",
            "Scraping category: Academic\n",
            "Scraping category: Self Help\n",
            "Scraping category: Historical\n",
            "Scraping category: Christian\n",
            "Scraping category: Suspense\n",
            "Scraping category: Short Stories\n",
            "Scraping category: Novels\n",
            "Scraping category: Health\n",
            "Scraping category: Politics\n",
            "Scraping category: Cultural\n",
            "Scraping category: Erotica\n",
            "Scraping category: Crime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(final_data)\n",
        "#add new column for EUR prices\n",
        "df.insert(0, 'ID', range(1, 1 + len(df)))\n",
        "df['Price (EUR)'] = (df['Price (GBP)'] * rate).round(2)\n",
        "df['Exchange Date'] = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "df.to_csv('books_data.csv', index=False, encoding='utf-8')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ikfmEfIKnyKI",
        "outputId": "80bb12ea-6b3b-4bd7-ee73-b6683b162189"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       ID                                              title  Price (GBP)  \\\n",
            "0       1                            It's Only the Himalayas        45.17   \n",
            "1       2  Full Moon over Noahâ€™s Ark: An Odyssey to Mount...        49.43   \n",
            "2       3  See America: A Celebration of Our National Par...        48.87   \n",
            "3       4  Vagabonding: An Uncommon Guide to the Art of L...        36.94   \n",
            "4       5                               Under the Tuscan Sun        37.33   \n",
            "..    ...                                                ...          ...   \n",
            "995   996  Why the Right Went Wrong: Conservatism--From G...        52.65   \n",
            "996   997  Equal Is Unfair: America's Misguided Fight Aga...        56.86   \n",
            "997   998                                     Amid the Chaos        36.58   \n",
            "998   999                                         Dark Notes        19.19   \n",
            "999  1000  The Long Shadow of Small Ghosts: Murder and Me...        10.97   \n",
            "\n",
            "     category  Price (EUR) Exchange Date  \n",
            "0      Travel        51.84    2026-01-22  \n",
            "1      Travel        56.73    2026-01-22  \n",
            "2      Travel        56.08    2026-01-22  \n",
            "3      Travel        42.39    2026-01-22  \n",
            "4      Travel        42.84    2026-01-22  \n",
            "..        ...          ...           ...  \n",
            "995  Politics        60.42    2026-01-22  \n",
            "996  Politics        65.25    2026-01-22  \n",
            "997  Cultural        41.98    2026-01-22  \n",
            "998   Erotica        22.02    2026-01-22  \n",
            "999     Crime        12.59    2026-01-22  \n",
            "\n",
            "[1000 rows x 6 columns]\n"
          ]
        }
      ]
    }
  ]
}