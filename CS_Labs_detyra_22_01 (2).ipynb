{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iTautcw6kSEH"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import time\n",
        "from urllib.parse import urljoin\n",
        "from datetime import datetime\n",
        "from os import name\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "homepage_url = \"http://books.toscrape.com/\"\n",
        "homepage_response = requests.get(homepage_url)\n",
        "homepage_response.encoding = 'utf-8' #per ruajtjen e cmimit\n",
        "homepage_soup = BeautifulSoup(homepage_response.text, 'html.parser')"
      ],
      "metadata": {
        "id": "0W2fPwXGkaCp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting a category list with the category name and the corresponding link\n",
        "\n",
        "def get_categories():\n",
        "  response = requests.get(homepage_url)\n",
        "  response.encoding = 'utf-8'\n",
        "  soup = BeautifulSoup(response.text, 'html.parser')\n",
        "  categories_tags = soup.select_one('div.side_categories > ul > li > ul').find_all('li', recursive = False)\n",
        "  categories = {}\n",
        "  for tag in categories_tags:\n",
        "    name = tag.text.strip()\n",
        "    link = urljoin(homepage_url, tag.find('a')['href'])\n",
        "    categories[name] = link\n",
        "  return categories"
      ],
      "metadata": {
        "id": "BLEJWDEwwgoM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books={}\n",
        "\n",
        "#get all books from all pages of a specific category\n",
        "def scrape_category(category_name, start_url):\n",
        "  current_url = start_url\n",
        "\n",
        "  while current_url:\n",
        "    response = requests.get(current_url)\n",
        "    response.encoding = 'utf-8'\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    for article in soup.find_all('article', class_='product_pod'):\n",
        "      title = article.h3.a['title']\n",
        "      #if book is already scraped, then we add the other category\n",
        "      if title in books:\n",
        "        books[title]['Categories'].add(category_name)\n",
        "      else:\n",
        "        price = article.find('p', class_='price_color').text\n",
        "        clean_price = float(re.findall(r'[0-9.]+', price)[0])\n",
        "        #adds all books of the current page\n",
        "        books[title] = {\n",
        "            'Title': title,\n",
        "            'Price (GBP)': clean_price,\n",
        "            'Categories': {category_name}\n",
        "        }\n",
        "# also checking for pagination, if there's other pages, we scrape those too\n",
        "    next_button = soup.find('li', class_='next')\n",
        "    if next_button:\n",
        "      relative_link = next_button.find('a')['href']\n",
        "      current_url = urljoin(current_url, relative_link)\n",
        "    else:\n",
        "      current_url = None\n",
        "\n",
        "  return books\n",
        "\n",
        "all_categories = get_categories()\n",
        "for category_name, link in all_categories.items():\n",
        "  print(f\"Scraping category: {category_name}\")\n",
        "  scrape_category(category_name, link)"
      ],
      "metadata": {
        "id": "R3AvPt8rzGLX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c587ced8-40b4-48fc-b3d7-4d19d3525ca0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraping category: Travel\n",
            "Scraping category: Mystery\n",
            "Scraping category: Historical Fiction\n",
            "Scraping category: Sequential Art\n",
            "Scraping category: Classics\n",
            "Scraping category: Philosophy\n",
            "Scraping category: Romance\n",
            "Scraping category: Womens Fiction\n",
            "Scraping category: Fiction\n",
            "Scraping category: Childrens\n",
            "Scraping category: Religion\n",
            "Scraping category: Nonfiction\n",
            "Scraping category: Music\n",
            "Scraping category: Default\n",
            "Scraping category: Science Fiction\n",
            "Scraping category: Sports and Games\n",
            "Scraping category: Add a comment\n",
            "Scraping category: Fantasy\n",
            "Scraping category: New Adult\n",
            "Scraping category: Young Adult\n",
            "Scraping category: Science\n",
            "Scraping category: Poetry\n",
            "Scraping category: Paranormal\n",
            "Scraping category: Art\n",
            "Scraping category: Psychology\n",
            "Scraping category: Autobiography\n",
            "Scraping category: Parenting\n",
            "Scraping category: Adult Fiction\n",
            "Scraping category: Humor\n",
            "Scraping category: Horror\n",
            "Scraping category: History\n",
            "Scraping category: Food and Drink\n",
            "Scraping category: Christian Fiction\n",
            "Scraping category: Business\n",
            "Scraping category: Biography\n",
            "Scraping category: Thriller\n",
            "Scraping category: Contemporary\n",
            "Scraping category: Spirituality\n",
            "Scraping category: Academic\n",
            "Scraping category: Self Help\n",
            "Scraping category: Historical\n",
            "Scraping category: Christian\n",
            "Scraping category: Suspense\n",
            "Scraping category: Short Stories\n",
            "Scraping category: Novels\n",
            "Scraping category: Health\n",
            "Scraping category: Politics\n",
            "Scraping category: Cultural\n",
            "Scraping category: Erotica\n",
            "Scraping category: Crime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_exchange_rate(api_key, base_currency, target_currency):\n",
        "  url = f\"https://v6.exchangerate-api.com/v6/{api_key}/latest/{base_currency}\"\n",
        "  response = requests.get(url)\n",
        "  data = response.json()\n",
        "\n",
        "  if data[\"result\"] == \"success\":\n",
        "    return data[\"conversion_rates\"][target_currency]\n",
        "  else:\n",
        "    print(\"Error fetching API data!\")\n",
        "    return None\n",
        "\n",
        "API_KEY = \"\"\n",
        "\n",
        "rate = get_exchange_rate(API_KEY, \"GBP\", \"EUR\")\n",
        "\n",
        "print(\"Exchange Rate GBP->EUR: \", rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFlyq5s0pZe5",
        "outputId": "8def9527-db98-4289-8329-31141bd6c82f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exchange Rate GBP->EUR:  1.151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_list = list(books.values())\n",
        "for item in final_list:\n",
        "  item['Categories'] = ', '.join(sorted(item['Categories']))\n",
        "\n",
        "df = pd.DataFrame(final_list)\n",
        "\n",
        "#shtohet kolona per ID\n",
        "df.insert(0, 'ID', range(1, 1 + len(df)))\n",
        "\n",
        "#shtohet kolona per cmimin ne EUR\n",
        "df['Price (EUR)'] = (df['Price (GBP)'] * rate).round(2)\n",
        "\n",
        "#shtohet kolona per daten e kembimit\n",
        "df['Exchange Date'] = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "#krijohet file .csv\n",
        "df.to_csv('books_data.csv', index=False, encoding='utf-8')\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikfmEfIKnyKI",
        "outputId": "8d5629d6-652f-4dbc-cf9d-0ab2b54928e2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      ID                                              Title  Price (GBP)  \\\n",
            "0      1                            It's Only the Himalayas        45.17   \n",
            "1      2  Full Moon over Noahâ€™s Ark: An Odyssey to Mount...        49.43   \n",
            "2      3  See America: A Celebration of Our National Par...        48.87   \n",
            "3      4  Vagabonding: An Uncommon Guide to the Art of L...        36.94   \n",
            "4      5                               Under the Tuscan Sun        37.33   \n",
            "..   ...                                                ...          ...   \n",
            "994  995  Why the Right Went Wrong: Conservatism--From G...        52.65   \n",
            "995  996  Equal Is Unfair: America's Misguided Fight Aga...        56.86   \n",
            "996  997                                     Amid the Chaos        36.58   \n",
            "997  998                                         Dark Notes        19.19   \n",
            "998  999  The Long Shadow of Small Ghosts: Murder and Me...        10.97   \n",
            "\n",
            "                Categories  Price (EUR) Exchange Date  \n",
            "0    Test Category, Travel        51.99    2026-01-28  \n",
            "1                   Travel        56.89    2026-01-28  \n",
            "2                   Travel        56.25    2026-01-28  \n",
            "3                   Travel        42.52    2026-01-28  \n",
            "4                   Travel        42.97    2026-01-28  \n",
            "..                     ...          ...           ...  \n",
            "994               Politics        60.60    2026-01-28  \n",
            "995               Politics        65.45    2026-01-28  \n",
            "996               Cultural        42.10    2026-01-28  \n",
            "997                Erotica        22.09    2026-01-28  \n",
            "998                  Crime        12.63    2026-01-28  \n",
            "\n",
            "[999 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual test: Add 'Test Category' to the first book found\n",
        "first_book_title = list(books.keys())[0]\n",
        "books[first_book_title]['Categories'].add('Test Category')"
      ],
      "metadata": {
        "id": "eKBRiFR-NioH"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}
